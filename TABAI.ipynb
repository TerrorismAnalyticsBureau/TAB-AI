{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOLQbggjzOq3KEr5LGMapAQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TerrorismAnalyticsBureau/TAB-AI/blob/main/TABAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "fh97AMOCu5q5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        },
        "outputId": "d954aac0-6401-4ee6-a5c6-5611d019163f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-28-dba860546d5a>:27: DtypeWarning: Columns (4,6,31,33,61,62,63,76,79,90,92,94,96,114,115,121) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  data = pd.read_csv('./globalterrorismdb_0718dist.csv', encoding=\"Windows-1252\")\n",
            "<ipython-input-28-dba860546d5a>:48: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  data['imonth'].fillna(pd.to_datetime(1), inplace=True)\n",
            "<ipython-input-28-dba860546d5a>:49: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  data['iday'].fillna(pd.to_datetime(1), inplace=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-dba860546d5a>\u001b[0m in \u001b[0;36m<cell line: 200>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;31m# Forward pass: compute predicted y by passing X to the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_date\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;31m# Compute the loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-28-dba860546d5a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;31m# Initialize the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as func\n",
        "import torch.optim as optim\n",
        "import os\n",
        "from datetime import datetime\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# ------------------------------ Data Preprocessing ------------------------------\n",
        "\n",
        "# Set pyTorch local env to use segmented GPU memory\n",
        "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
        "\n",
        "# Clear GPU cache & Set the device to use GPU\n",
        "torch.cuda.empty_cache()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load dataset\n",
        "# Skip rows = 1 because those are the column names\n",
        "X = np.array([])\n",
        "\n",
        "# Read the file using its encoding\n",
        "data = pd.read_csv('./globalterrorismdb_0718dist.csv', encoding=\"Windows-1252\")\n",
        "\n",
        "# Extract relevant columns (adjust indices or column names as needed)\n",
        "input_columns = data.iloc[:, [1, 2, 3, 7, 11]]\n",
        "input_columns = input_columns.fillna(0)\n",
        "\n",
        "# Convert non-numeric to numeric and fill missing values\n",
        "for col in input_columns.columns:\n",
        "    input_columns[col] = pd.to_numeric(input_columns[col], errors='coerce')  # Convert non-numeric to NaN\n",
        "input_columns = input_columns.fillna(0)  # Replace NaN with 0\n",
        "\n",
        "attack_target = data.iloc[:, [28]]\n",
        "group_target = data.iloc[:, [58]]\n",
        "\n",
        "# Set the base date (last day of 2017)\n",
        "last_date = datetime(2017, 12, 31)\n",
        "\n",
        "# Convert last date to numeric form\n",
        "last_date_numeric = last_date.toordinal()\n",
        "\n",
        "# Get date from dataset\n",
        "data['imonth'].fillna(pd.to_datetime(1), inplace=True)\n",
        "data['iday'].fillna(pd.to_datetime(1), inplace=True)\n",
        "\n",
        "data['date_str'] = data['iyear'].astype(str) + '-' + data['imonth'].astype(str).str.zfill(2) + '-' + data['iday'].astype(str).str.zfill(2)\n",
        "data['date'] = pd.to_datetime(data['date_str'], errors='coerce')\n",
        "\n",
        "\n",
        "# Convert dates to numeric by subtracting the last date of 2017\n",
        "# Get number of days since Dec 31, 2017\n",
        "data['date_numeric'] = (data['date'] - last_date).dt.days\n",
        "\n",
        "# Extract unique values\n",
        "unique_attacks = list(set(data['attacktype1_txt']))\n",
        "unique_groups = list(set(data['gname']))\n",
        "unique_provstates = list(set(data['provstate']))\n",
        "unique_cities = list(set(data['city']))\n",
        "\n",
        "# Initialize LabelEncoder and fit to the unique groups\n",
        "attack_encoder = LabelEncoder()\n",
        "attack_encoder.fit(unique_attacks)\n",
        "\n",
        "group_encoder = LabelEncoder()\n",
        "group_encoder.fit(unique_groups)\n",
        "\n",
        "provstate_encoder = LabelEncoder()\n",
        "provstate_encoder.fit(unique_provstates)\n",
        "\n",
        "city_encoder = LabelEncoder()\n",
        "city_encoder.fit(unique_cities)\n",
        "\n",
        "# Set the output size based on the number of unique attack types\n",
        "num_attack_types = len(unique_attacks)\n",
        "num_groups = len(unique_groups)\n",
        "num_cities = len(unique_cities)\n",
        "num_provstates = len(unique_provstates)\n",
        "\n",
        "# Create a dictionary to map names to their encoded IDs\n",
        "group_dict = pd.Series(group_encoder.transform(unique_groups), index=unique_groups)\n",
        "provstate_dict = pd.Series(provstate_encoder.transform(unique_provstates), index=unique_provstates)\n",
        "city_dict = pd.Series(city_encoder.transform(unique_cities), index=unique_cities)\n",
        "\n",
        "# Assign values to tensors for processing\n",
        "input_tensor = torch.tensor(input_columns.to_numpy(), dtype=torch.float32)\n",
        "attack_target_tensor = torch.tensor(attack_target.values, dtype=torch.float32)\n",
        "group_target_tensor = torch.tensor(group_encoder.fit_transform(group_target.values), dtype=torch.float32)\n",
        "city_target_tensor = torch.tensor(city_encoder.fit_transform(data['city'].values), dtype=torch.float32)\n",
        "provstate_target_tensor = torch.tensor(provstate_encoder.fit_transform(data['provstate'].values), dtype=torch.float32)\n",
        "\n",
        "# TESTING - PRINT DICTIONARY ITEMS\n",
        "#for key, value in group_dict.items():\n",
        "#  print(\"group: \", key, \"| ID #:\", value)\n",
        "\n",
        "#for key, value in provstate_dict.items():\n",
        "#  print(\"provstate: \", key, \"| ID #:\", value)\n",
        "\n",
        "#for key, value in city_dict.items():\n",
        "#  print(\"city: \", key, \"| ID #:\", value)\n",
        "\n",
        "# Assign values to tensors for processing\n",
        "X_tensor = input_tensor\n",
        "\n",
        "# Normalize: mean and std for each feature\n",
        "mean = X_tensor.mean(dim=0, keepdim=True)\n",
        "std = X_tensor.std(dim=0, keepdim=True)\n",
        "X_tensor = (X_tensor - mean) / std\n",
        "\n",
        "Y_tensor_attack = attack_target_tensor\n",
        "Y_tensor_group = group_target_tensor\n",
        "Y_tensor_city = city_target_tensor\n",
        "Y_tensor_provstate = provstate_target_tensor\n",
        "Y_tensor_date = torch.tensor(data['date_numeric'] - last_date_numeric, dtype=torch.float32)\n",
        "\n",
        "# Set tensors to use GPU\n",
        "X_tensor = X_tensor.to(device)\n",
        "Y_tensor_attack = Y_tensor_attack.to(device)\n",
        "Y_tensor_group = Y_tensor_group.to(device)\n",
        "Y_tensor_city = Y_tensor_city.to(device)\n",
        "Y_tensor_provstate = Y_tensor_provstate.to(device)\n",
        "Y_tensor_date = Y_tensor_date.to(device)\n",
        "\n",
        "# ------------------------------ LSTM Prediction Model ------------------------------\n",
        "def train_model(X_tensor, Y_tensor, num_classes, sequence_length=30, hidden_size=128, num_epochs=10, batch_size=32):\n",
        "    class LSTMPredictor(nn.Module):\n",
        "        def __init__(self, input_size, hidden_size, output_size):\n",
        "            super(LSTMPredictor, self).__init__()\n",
        "            self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
        "            self.dropout = nn.Dropout(0.2)\n",
        "            self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "        def forward(self, x):\n",
        "            lstm_out, _ = self.lstm(x)\n",
        "            lstm_out = self.dropout(lstm_out)\n",
        "            logits = self.fc(lstm_out[:, -1, :])\n",
        "            return logits\n",
        "\n",
        "    # Create sequences\n",
        "    def create_sequences(input_data, seq_length):\n",
        "        sequences = []\n",
        "        for i in range(len(input_data) - seq_length + 1):\n",
        "            seq = input_data[i:i + seq_length]\n",
        "            sequences.append(seq)\n",
        "        return torch.stack(sequences)\n",
        "\n",
        "    sequences = create_sequences(X_tensor, sequence_length)\n",
        "\n",
        "    # Create DataLoader\n",
        "    dataset = TensorDataset(sequences, Y_tensor[:len(sequences)])\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    # Initialize model, loss, and optimizer\n",
        "    model = LSTMPredictor(input_size=X_tensor.shape[1], hidden_size=hidden_size, output_size=num_classes).to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        for batch_x, batch_y in dataloader:\n",
        "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(batch_x)\n",
        "            if batch_y.ndim > 1:\n",
        "                batch_y = batch_y.argmax(dim=1)  # Convert one-hot to indices\n",
        "            batch_y = batch_y.long()  # Ensure correct type\n",
        "\n",
        "            loss = criterion(outputs, batch_y)\n",
        "\n",
        "            # Backward pass and optimization\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
        "\n",
        "    return model\n",
        "\n",
        "# ------------------------------ Linear Regression Prediction Model ------------------------------\n",
        "\n",
        "class LinearRegressionModel(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(LinearRegressionModel, self).__init__()\n",
        "        self.linear = nn.Linear(input_dim, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear(x)\n",
        "\n",
        "# Initialize the model\n",
        "model_date = LinearRegressionModel(X_tensor.shape[1])\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.SGD(model_date.parameters(), lr=0.001)\n",
        "\n",
        "epochs = 1000  # Number of training epochs\n",
        "for epoch in range(epochs):\n",
        "    model_date.train()\n",
        "    optimizer.zero_grad()  # Zero the gradients\n",
        "\n",
        "    # Forward pass: compute predicted y by passing X to the model\n",
        "    y_pred = model_date(X_tensor)\n",
        "\n",
        "    # Compute the loss\n",
        "    loss = criterion(y_pred, Y_tensor_date)\n",
        "\n",
        "    # Backward pass: compute gradients\n",
        "    loss.backward()\n",
        "\n",
        "    # Update the model parameters\n",
        "    optimizer.step()\n",
        "\n",
        "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
        "\n",
        "# ------------------------------ Train & Evaluate Models ------------------------------\n",
        "model_attack = train_model(X_tensor, Y_tensor_attack, num_classes=num_attack_types)\n",
        "model_attack = model_attack.to(device)\n",
        "\n",
        "model_groups = train_model(X_tensor, Y_tensor_group, num_classes=num_groups)\n",
        "model_groups = model_groups.to(device)\n",
        "\n",
        "model_city = train_model(X_tensor, Y_tensor_city, num_classes=num_cities)\n",
        "model_city = model_city.to(device)\n",
        "\n",
        "model_provstate = train_model(X_tensor, Y_tensor_provstate, num_classes=num_provstates)\n",
        "model_provstate = model_provstate.to(device)\n",
        "\n",
        "model_date = LinearRegressionModel(X_tensor.shape[1])\n",
        "model_date = model_date.to(device)\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "model_attack.eval()\n",
        "model_groups.eval()\n",
        "model_city.eval()\n",
        "model_provstate.eval()\n",
        "model_date.eval()\n",
        "\n",
        "# ------------------------------ Testing ------------------------------\n",
        "with torch.no_grad():\n",
        "    # Prepare the most recent sequence for prediction\n",
        "    recent_sequence = X_tensor[-1:].unsqueeze(0).to(device)  # Add batch dimension\n",
        "\n",
        "    # Model 1: Attack prediction\n",
        "    prediction_attack = model_attack(recent_sequence)  # Get model's prediction (logits)\n",
        "    # Get the predicted class (argmax of logits)\n",
        "    predicted_class_attack = torch.argmax(prediction_attack, dim=1).item()  # Convert logits to class index\n",
        "    # Decode the predicted class back to attack type using the encoder\n",
        "    attack_type = attack_encoder.inverse_transform([predicted_class_attack])\n",
        "    print(\"Predicted Attack Type:\", attack_type[0])\n",
        "\n",
        "    # Model 2: Group prediction\n",
        "    prediction_group = model_groups(recent_sequence)  # Get model's prediction (logits)\n",
        "    # Get the predicted class (argmax of logits)\n",
        "    predicted_class_group = torch.argmax(prediction_group, dim=1).item()  # Convert logits to class index\n",
        "    # Decode the predicted class back to attack type using the encoder\n",
        "    group_name = group_encoder.inverse_transform([predicted_class_group])\n",
        "    print(\"Predicted Group Name:\", group_name[0])\n",
        "\n",
        "    # Model 3: City prediction\n",
        "    prediction_city = model_city(recent_sequence)  # Get model's prediction (logits)\n",
        "    # Get the predicted class (argmax of logits)\n",
        "    predicted_class_city = torch.argmax(prediction_city, dim=1).item()  # Convert logits to class index\n",
        "    # Decode the predicted class back to attack type using the encoder\n",
        "    city_name = city_encoder.inverse_transform([predicted_class_city])\n",
        "    print(\"Predicted City Name:\", city_name[0])\n",
        "\n",
        "    # Model 4: provstate prediction\n",
        "    prediction_provstate = model_provstate(recent_sequence)  # Get model's prediction (logits)\n",
        "    # Get the predicted class (argmax of logits)\n",
        "    predicted_class_provstate = torch.argmax(prediction_provstate, dim=1).item()  # Convert logits to class index\n",
        "    # Decode the predicted class back to attack type using the encoder\n",
        "    provstate_name = provstate_encoder.inverse_transform([predicted_class_provstate])\n",
        "    print(\"Predicted State Name:\", provstate_name[0])\n",
        "\n",
        "    # Model 5: Date prediction\n",
        "    # Predict the offset (number of days) for a new input\n",
        "    future_input = torch.tensor([X_tensor]).unsqueeze(0).to(device)  # Replace with actual input features\n",
        "    predicted_offset = model_date(future_input).item()  # Get the predicted offset in days\n",
        "    # Calculate the predicted numeric date (days since Dec 31, 2017)\n",
        "    predicted_numeric_date = last_date_numeric + predicted_offset\n",
        "\n",
        "    # Convert the predicted numeric date back to a datetime object\n",
        "    predicted_date = datetime.fromordinal(predicted_numeric_date)\n",
        "\n",
        "    print(\"Predicted Date:\", predicted_date)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "name (csv column number)\n",
        "```\n",
        "•    iyear (1), imonth (2), iday (3)\n",
        "•    country code (7) and country_txt (8)\n",
        "•    region code (9) and region_txt (10)\n",
        "•    provstate (11) and city (12)\n",
        "•    latitude (13) and longitude (14)\n",
        "•    attacktype1 (28) and attacktype1_txt (29)\n",
        "•    targtype1 (34) and targtype1_txt (35)\n",
        "•    targsubtype1 (36) and targsubtype1_txt (37)\n",
        "•    target1 (39) (the specific target by name, building or person)\n",
        "\n",
        "•    natity1 (40) and natity1_txt (41) (maybe later)\n",
        "•    gname (group name) (58)\n",
        "•    weaptype1 (81) and weaptype1_txt (82) (maybe)\n",
        "•    nkill (98) and nwound (101)\n",
        "\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "nK7HLnxk5jkd"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cwWeI-IbsnsI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}