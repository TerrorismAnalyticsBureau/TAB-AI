{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNbzpz8CXfCaTi3FkIIOJI4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TerrorismAnalyticsBureau/TAB-AI/blob/main/TABAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "fh97AMOCu5q5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7d6777f6-a31b-4d40-e415-000581f5d4f3"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-6-bcddd580f38d>:28: DtypeWarning: Columns (4,6,31,33,61,62,63,76,79,90,92,94,96,114,115,121) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  data = pd.read_csv('./globalterrorismdb_0718dist.csv', encoding=\"Windows-1252\")\n",
            "<ipython-input-6-bcddd580f38d>:41: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0. 0. 0. ... 1. 1. 1.]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  input_columns.iloc[:, :3] = scaler.fit_transform(input_columns.iloc[:, :3].astype(float))\n",
            "<ipython-input-6-bcddd580f38d>:41: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0.58333333 0.         0.08333333 ... 1.         1.         1.        ]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  input_columns.iloc[:, :3] = scaler.fit_transform(input_columns.iloc[:, :3].astype(float))\n",
            "<ipython-input-6-bcddd580f38d>:41: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0.06451613 0.         0.         ... 1.         1.         1.        ]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  input_columns.iloc[:, :3] = scaler.fit_transform(input_columns.iloc[:, :3].astype(float))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.0000\n",
            "Epoch [2/10], Loss: 0.0000\n",
            "Epoch [3/10], Loss: 0.0000\n",
            "Epoch [4/10], Loss: 0.0000\n",
            "Epoch [5/10], Loss: 0.0000\n",
            "Epoch [6/10], Loss: 0.0000\n",
            "Epoch [7/10], Loss: 0.0000\n",
            "Epoch [8/10], Loss: 0.0000\n",
            "Epoch [9/10], Loss: 0.0000\n",
            "Epoch [10/10], Loss: 0.0000\n",
            "Epoch [1/10], Loss: 0.0000\n",
            "Epoch [2/10], Loss: 0.0000\n",
            "Epoch [3/10], Loss: 0.0000\n",
            "Epoch [4/10], Loss: 0.0000\n",
            "Epoch [5/10], Loss: 0.0000\n",
            "Epoch [6/10], Loss: 0.0000\n",
            "Epoch [7/10], Loss: 0.0000\n",
            "Epoch [8/10], Loss: 0.0000\n",
            "Epoch [9/10], Loss: 0.0000\n",
            "Epoch [10/10], Loss: 0.0000\n",
            "Epoch [1/10], Loss: 0.4846\n",
            "Epoch [2/10], Loss: 0.0046\n",
            "Epoch [3/10], Loss: 0.0046\n",
            "Epoch [4/10], Loss: 0.2493\n",
            "Epoch [5/10], Loss: 0.0052\n",
            "Epoch [6/10], Loss: 0.0049\n",
            "Epoch [7/10], Loss: 0.0040\n",
            "Epoch [8/10], Loss: 0.0093\n",
            "Epoch [9/10], Loss: 0.0080\n",
            "Epoch [10/10], Loss: 0.0034\n",
            "Epoch [1/10], Loss: 8.5360\n",
            "Epoch [2/10], Loss: 6.0025\n",
            "Epoch [3/10], Loss: 7.2130\n",
            "Epoch [4/10], Loss: 7.7875\n",
            "Epoch [5/10], Loss: 6.2827\n",
            "Epoch [6/10], Loss: 4.8485\n",
            "Epoch [7/10], Loss: 6.0033\n",
            "Epoch [8/10], Loss: 4.7497\n",
            "Epoch [9/10], Loss: 6.6185\n",
            "Epoch [10/10], Loss: 6.8585\n",
            "Epoch [1/10], Loss: 4.0814\n",
            "Epoch [2/10], Loss: 3.9053\n",
            "Epoch [3/10], Loss: 2.5701\n",
            "Epoch [4/10], Loss: 2.6451\n",
            "Epoch [5/10], Loss: 2.4561\n",
            "Epoch [6/10], Loss: 2.6789\n",
            "Epoch [7/10], Loss: 2.3918\n",
            "Epoch [8/10], Loss: 2.6178\n",
            "Epoch [9/10], Loss: 4.0813\n",
            "Epoch [10/10], Loss: 3.4205\n",
            "Epoch [1/10], Loss: 0.0000\n",
            "Epoch [2/10], Loss: 0.0000\n",
            "Epoch [3/10], Loss: 0.0000\n",
            "Epoch [4/10], Loss: 0.0000\n",
            "Epoch [5/10], Loss: 0.0000\n",
            "Epoch [6/10], Loss: 0.0000\n",
            "Epoch [7/10], Loss: 0.0000\n",
            "Epoch [8/10], Loss: 0.0000\n",
            "Epoch [9/10], Loss: 0.0000\n",
            "Epoch [10/10], Loss: 0.0000\n",
            "Predicted Attack Type: Armed Assault\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "y contains previously unseen labels: [110]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-bcddd580f38d>\u001b[0m in \u001b[0;36m<cell line: 187>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0mpredicted_class_group\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction_group\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Convert logits to class index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0;31m# Decode the predicted class back to attack type using the encoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m     \u001b[0mgroup_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattack_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpredicted_class_group\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Predicted Group Name:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_name\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_label.py\u001b[0m in \u001b[0;36minverse_transform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdiff1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y contains previously unseen labels: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: y contains previously unseen labels: [110]"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as func\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import os\n",
        "import chardet\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# ------------------------------ Data Preprocessing ------------------------------\n",
        "\n",
        "# Set pyTorch local env to use segmented GPU memory\n",
        "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
        "\n",
        "# Clear GPU cache & Set the device to use GPU\n",
        "torch.cuda.empty_cache()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load dataset\n",
        "# Skip rows = 1 because those are the column names\n",
        "X = np.array([])\n",
        "\n",
        "# Now, read the file using the detected encoding\n",
        "data = pd.read_csv('./globalterrorismdb_0718dist.csv', encoding=\"Windows-1252\")\n",
        "\n",
        "# Extract relevant columns (adjust indices or column names as needed)\n",
        "input_columns = data.iloc[:, [1, 2, 3, 7, 11]]\n",
        "input_columns = input_columns.fillna(0)\n",
        "\n",
        "# Convert non-numeric to numeric and fill missing values\n",
        "for col in input_columns.columns:\n",
        "    input_columns[col] = pd.to_numeric(input_columns[col], errors='coerce')  # Convert non-numeric to NaN\n",
        "input_columns = input_columns.fillna(0)  # Replace NaN with 0\n",
        "\n",
        "# Normalize the first three columns\n",
        "scaler = MinMaxScaler()\n",
        "input_columns.iloc[:, :3] = scaler.fit_transform(input_columns.iloc[:, :3].astype(float))\n",
        "\n",
        "attack_target = data.iloc[:, [28]]\n",
        "group_target = data.iloc[:, [57]]\n",
        "date_target = data.iloc[:, [1, 2, 3]]\n",
        "\n",
        "# Extract unique group names\n",
        "unique_groups = list(set(data['gname']))\n",
        "unique_provstates = list(set(data['provstate']))\n",
        "unique_cities = list(set(data['city']))\n",
        "\n",
        "attack_encoder = LabelEncoder()\n",
        "attack_encoder.fit(data['attacktype1_txt'].unique())  # Fit to unique attack types in the text column\n",
        "\n",
        "# Encode the attack types numerically based on attacktype1 (which will be your target)\n",
        "attack_target_tensor = torch.tensor(data['attacktype1'].values, dtype=torch.long)\n",
        "\n",
        "# Set the output size based on the number of unique attack types\n",
        "num_attack_types = len(attack_encoder.classes_)\n",
        "num_groups = len(unique_groups)\n",
        "num_provstates = len(unique_provstates)\n",
        "num_cities = len(unique_cities)\n",
        "num_dates = len(date_target)\n",
        "\n",
        "# Initialize LabelEncoder and fit to the unique groups\n",
        "group_encoder = LabelEncoder()\n",
        "group_encoder.fit(unique_groups)\n",
        "\n",
        "provstate_encoder = LabelEncoder()\n",
        "provstate_encoder.fit(unique_provstates)\n",
        "\n",
        "city_encoder = LabelEncoder()\n",
        "city_encoder.fit(unique_cities)\n",
        "\n",
        "# Create a dictionary to map names to their encoded IDs\n",
        "group_dict = pd.Series(group_encoder.transform(unique_groups), index=unique_groups)\n",
        "provstate_dict = pd.Series(provstate_encoder.transform(unique_provstates), index=unique_provstates)\n",
        "city_dict = pd.Series(city_encoder.transform(unique_cities), index=unique_cities)\n",
        "\n",
        "# Assign values to tensors for processing\n",
        "input_tensor = torch.tensor(input_columns.to_numpy(), dtype=torch.float32)\n",
        "attack_target_tensor = torch.tensor(attack_target.values, dtype=torch.float32)\n",
        "group_target_tensor = torch.tensor(group_encoder.fit_transform(group_target.values), dtype=torch.float32)\n",
        "date_target_tensor = torch.tensor(date_target.values, dtype=torch.float32)\n",
        "provstate_target_tensor = torch.tensor(provstate_encoder.fit_transform(data['provstate'].values), dtype=torch.float32)\n",
        "city_target_tensor = torch.tensor(city_encoder.fit_transform(data['city'].values), dtype=torch.float32)\n",
        "\n",
        "# TESTING - PRINT DICTIONARY ITEMS\n",
        "#for key, value in group_dict.items():\n",
        "#  print(\"group: \", key, \"| ID #:\", value)\n",
        "\n",
        "#for key, value in provstate_dict.items():\n",
        "#  print(\"provstate: \", key, \"| ID #:\", value)\n",
        "\n",
        "#for key, value in city_dict.items():\n",
        "#  print(\"city: \", key, \"| ID #:\", value)\n",
        "\n",
        "# Assign values to tensors for processing\n",
        "X_tensor = input_tensor\n",
        "Y_tensor_attack = attack_target_tensor\n",
        "Y_tensor_group = group_target_tensor\n",
        "Y_tensor_date = date_target_tensor\n",
        "Y_tensor_provstate = provstate_target_tensor\n",
        "Y_tensor_city = city_target_tensor\n",
        "\n",
        "# Set tensors to use GPU\n",
        "X_tensor = X_tensor.to(device)\n",
        "Y_tensor_attack = Y_tensor_attack.to(device)\n",
        "Y_tensor_group = Y_tensor_group.to(device)\n",
        "Y_tensor_provstate = Y_tensor_provstate.to(device)\n",
        "Y_tensor_date = Y_tensor_date.to(device)\n",
        "Y_tensor_city = Y_tensor_city.to(device)\n",
        "\n",
        "# ------------------------------ Prediction Model ------------------------------\n",
        "def train_model(X_tensor, Y_tensor, num_classes, sequence_length=10, hidden_size=128, num_epochs=10, batch_size=32):\n",
        "    class LSTMPredictor(nn.Module):\n",
        "        def __init__(self, input_size, hidden_size, output_size):\n",
        "            super(LSTMPredictor, self).__init__()\n",
        "            self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
        "            self.dropout = nn.Dropout(0.2)\n",
        "            self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "        def forward(self, x):\n",
        "            lstm_out, _ = self.lstm(x)\n",
        "            lstm_out = self.dropout(lstm_out)\n",
        "            logits = self.fc(lstm_out[:, -1, :])\n",
        "            return logits\n",
        "\n",
        "    # Create sequences\n",
        "    def create_sequences(input_data, seq_length):\n",
        "        sequences = []\n",
        "        for i in range(len(input_data) - seq_length + 1):\n",
        "            seq = input_data[i:i + seq_length]\n",
        "            sequences.append(seq)\n",
        "        return torch.stack(sequences)\n",
        "\n",
        "    sequences = create_sequences(X_tensor, sequence_length)\n",
        "\n",
        "    # Create DataLoader\n",
        "    dataset = TensorDataset(sequences, Y_tensor[:len(sequences)])\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    # Initialize model, loss, and optimizer\n",
        "    model = LSTMPredictor(input_size=X_tensor.shape[1], hidden_size=hidden_size, output_size=num_classes).to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        for batch_x, batch_y in dataloader:\n",
        "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(batch_x)\n",
        "            if batch_y.ndim > 1:\n",
        "                batch_y = batch_y.argmax(dim=1)  # Convert one-hot to indices\n",
        "            batch_y = batch_y.long()  # Ensure correct type\n",
        "\n",
        "            loss = criterion(outputs, batch_y)\n",
        "\n",
        "            # Backward pass and optimization\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
        "\n",
        "    return model\n",
        "\n",
        "# ------------------------------ Train & Evaluate Models ------------------------------\n",
        "\n",
        "model_attack = train_model(X_tensor, Y_tensor_attack, num_classes=num_attack_types)\n",
        "model_attack = model_attack.to(device)\n",
        "\n",
        "model_groups = train_model(X_tensor, Y_tensor_group, num_classes=num_groups)\n",
        "model_groups = model_groups.to(device)\n",
        "\n",
        "model_city = train_model(X_tensor, Y_tensor_city, num_classes=num_cities)\n",
        "model_city = model_city.to(device)\n",
        "\n",
        "model_provstate = train_model(X_tensor, Y_tensor_provstate, num_classes=num_provstates)\n",
        "model_provstate = model_provstate.to(device)\n",
        "\n",
        "model_date = train_model(X_tensor, Y_tensor_date, num_classes=num_dates)\n",
        "model_date = model_date.to(device)\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "model_attack.eval()\n",
        "model_groups.eval()\n",
        "model_city.eval()\n",
        "model_provstate.eval()\n",
        "model_date.eval()\n",
        "\n",
        "# ------------------------------ Testing ------------------------------\n",
        "with torch.no_grad():\n",
        "    # Prepare the most recent sequence for prediction\n",
        "    recent_sequence = X_tensor[-1:].unsqueeze(0).to(device)  # Add batch dimension\n",
        "\n",
        "    # Model 1: Attack prediction\n",
        "    prediction_attack = model_attack(recent_sequence)  # Get model's prediction (logits)\n",
        "    # Get the predicted class (argmax of logits)\n",
        "    predicted_class_attack = torch.argmax(prediction_attack, dim=1).item()  # Convert logits to class index\n",
        "    # Decode the predicted class back to attack type using the encoder\n",
        "    attack_type = attack_encoder.inverse_transform([predicted_class_attack])\n",
        "    print(\"Predicted Attack Type:\", attack_type[0])\n",
        "\n",
        "    # Model 2: Group prediction\n",
        "    prediction_group = model_groups(recent_sequence)  # Get model's prediction (logits)\n",
        "    # Get the predicted class (argmax of logits)\n",
        "    predicted_class_group = torch.argmax(prediction_group, dim=1).item()  # Convert logits to class index\n",
        "    # Decode the predicted class back to attack type using the encoder\n",
        "    group_name = group_encoder.inverse_transform([predicted_class_group])\n",
        "    print(\"Predicted Group Name:\", group_name[0])\n",
        "\n",
        "    # Model 3: City prediction\n",
        "    prediction_city = model_city(recent_sequence)  # Get model's prediction (logits)\n",
        "    # Get the predicted class (argmax of logits)\n",
        "    predicted_class_city = torch.argmax(prediction_city, dim=1).item()  # Convert logits to class index\n",
        "    # Decode the predicted class back to attack type using the encoder\n",
        "    city_name = city_encoder.inverse_transform([predicted_class_city])\n",
        "    print(\"Predicted Group Name:\", city_name[0])\n",
        "\n",
        "    # Model 4: provstate prediction\n",
        "    prediction_provstate = model_provstate(recent_sequence)  # Get model's prediction (logits)\n",
        "    # Get the predicted class (argmax of logits)\n",
        "    predicted_class_provstate = torch.argmax(prediction_provstate, dim=1).item()  # Convert logits to class index\n",
        "    # Decode the predicted class back to attack type using the encoder\n",
        "    provstate_name = provstate_encoder.inverse_transform([predicted_class_provstate])\n",
        "    print(\"Predicted Group Name:\", provstate_name[0])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "name (csv column number)\n",
        "```\n",
        "•    iyear (1), imonth (2), iday (3)\n",
        "•    country code (7) and country_txt (8)\n",
        "•    region code (9) and region_txt (10)\n",
        "•    provstate (11) and city (12)\n",
        "•    latitude (13) and longitude (14)\n",
        "•    attacktype1 (28) and attacktype1_txt (29)\n",
        "•    targtype1 (34) and targtype1_txt (35)\n",
        "•    targsubtype1 (36) and targsubtype1_txt (37)\n",
        "•    target1 (39) (the specific target by name, building or person)\n",
        "\n",
        "•    natity1 (40) and natity1_txt (41) (maybe later)\n",
        "•    gname (group name) (57)\n",
        "•    weaptype1 (81) and weaptype1_txt (82) (maybe)\n",
        "•    nkill (98) and nwound (101)\n",
        "\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "nK7HLnxk5jkd"
      }
    }
  ]
}